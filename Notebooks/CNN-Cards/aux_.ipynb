{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e3d8db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase                            Cantidad\n",
      "==========================================\n",
      "ace of clubs                          120\n",
      "ace of diamonds                       129\n",
      "ace of hearts                         171\n",
      "ace of spades                         181\n",
      "eight of clubs                        138\n",
      "eight of diamonds                     159\n",
      "eight of hearts                       152\n",
      "eight of spades                       135\n",
      "five of clubs                         154\n",
      "five of diamonds                      151\n",
      "five of hearts                        136\n",
      "five of spades                        158\n",
      "four of clubs                         157\n",
      "four of diamonds                      114\n",
      "four of hearts                        154\n",
      "four of spades                        140\n",
      "jack of clubs                         171\n",
      "jack of diamonds                      160\n",
      "jack of hearts                        168\n",
      "jack of spades                        182\n",
      "joker                                 126\n",
      "king of clubs                         128\n",
      "king of diamonds                      135\n",
      "king of hearts                        125\n",
      "king of spades                        151\n",
      "nine of clubs                         124\n",
      "nine of diamonds                      129\n",
      "nine of hearts                        143\n",
      "nine of spades                        176\n",
      "queen of clubs                        154\n",
      "queen of diamonds                     163\n",
      "queen of hearts                       147\n",
      "queen of spades                       158\n",
      "seven of clubs                        108\n",
      "seven of diamonds                     124\n",
      "seven of hearts                       143\n",
      "seven of spades                       165\n",
      "six of clubs                          171\n",
      "six of diamonds                       139\n",
      "six of hearts                         135\n",
      "six of spades                         158\n",
      "ten of clubs                          149\n",
      "ten of diamonds                       151\n",
      "ten of hearts                         129\n",
      "ten of spades                         158\n",
      "three of clubs                        124\n",
      "three of diamonds                     158\n",
      "three of hearts                       113\n",
      "three of spades                       142\n",
      "two of clubs                          130\n",
      "two of diamonds                       133\n",
      "two of hearts                         155\n",
      "two of spades                         155\n",
      "==========================================\n",
      "TOTAL                                7729\n",
      "\n",
      "N√∫mero de clases: 53\n",
      "Promedio de im√°genes por clase: 145.8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "# Ruta al dataset\n",
    "DATA_PATH = './Datasets/Cards/train'\n",
    "\n",
    "# Contador de ejemplos por clase\n",
    "class_counts = defaultdict(int)\n",
    "total_images = 0\n",
    "\n",
    "# Recorrer todas las carpetas (clases)\n",
    "for class_folder in sorted(Path(DATA_PATH).iterdir()):\n",
    "    if class_folder.is_dir():\n",
    "        # Contar im√°genes (jpg y png)\n",
    "        num_images = len(list(class_folder.glob('*.jpg'))) + len(list(class_folder.glob('*.png')))\n",
    "        class_counts[class_folder.name] = num_images\n",
    "        total_images += num_images\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"{'Clase':<30} {'Cantidad':>10}\")\n",
    "print(\"=\" * 42)\n",
    "\n",
    "for class_name, count in sorted(class_counts.items()):\n",
    "    print(f\"{class_name:<30} {count:>10}\")\n",
    "\n",
    "print(\"=\" * 42)\n",
    "print(f\"{'TOTAL':<30} {total_images:>10}\")\n",
    "print(f\"\\nN√∫mero de clases: {len(class_counts)}\")\n",
    "print(f\"Promedio de im√°genes por clase: {total_images / len(class_counts):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdabb8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase                            Cantidad\n",
      "==========================================\n",
      "jack of spades                        182\n",
      "ace of spades                         181\n",
      "nine of spades                        176\n",
      "ace of hearts                         171\n",
      "jack of clubs                         171\n",
      "six of clubs                          171\n",
      "jack of hearts                        168\n",
      "seven of spades                       165\n",
      "queen of diamonds                     163\n",
      "jack of diamonds                      160\n",
      "eight of diamonds                     159\n",
      "five of spades                        158\n",
      "queen of spades                       158\n",
      "six of spades                         158\n",
      "ten of spades                         158\n",
      "three of diamonds                     158\n",
      "four of clubs                         157\n",
      "two of hearts                         155\n",
      "two of spades                         155\n",
      "five of clubs                         154\n",
      "four of hearts                        154\n",
      "queen of clubs                        154\n",
      "eight of hearts                       152\n",
      "five of diamonds                      151\n",
      "king of spades                        151\n",
      "ten of diamonds                       151\n",
      "ten of clubs                          149\n",
      "queen of hearts                       147\n",
      "nine of hearts                        143\n",
      "seven of hearts                       143\n",
      "three of spades                       142\n",
      "four of spades                        140\n",
      "six of diamonds                       139\n",
      "eight of clubs                        138\n",
      "five of hearts                        136\n",
      "eight of spades                       135\n",
      "king of diamonds                      135\n",
      "six of hearts                         135\n",
      "two of diamonds                       133\n",
      "two of clubs                          130\n",
      "ace of diamonds                       129\n",
      "nine of diamonds                      129\n",
      "ten of hearts                         129\n",
      "king of clubs                         128\n",
      "joker                                 126\n",
      "king of hearts                        125\n",
      "nine of clubs                         124\n",
      "seven of diamonds                     124\n",
      "three of clubs                        124\n",
      "ace of clubs                          120\n",
      "four of diamonds                      114\n",
      "three of hearts                       113\n",
      "seven of clubs                        108\n",
      "==========================================\n",
      "TOTAL                                7729\n"
     ]
    }
   ],
   "source": [
    "# Ordenar por cantidad de im√°genes de mayor a menor\n",
    "sorted_classes = sorted(class_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"{'Clase':<30} {'Cantidad':>10}\")\n",
    "print(\"=\" * 42)\n",
    "for name, cnt in sorted_classes:\n",
    "    print(f\"{name:<30} {cnt:>10}\")\n",
    "print(\"=\" * 42)\n",
    "print(f\"{'TOTAL':<30} {total_images:>10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "289b1368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'03a - SingleDetection-Tools'   SingleDetection-Tools   checkpoints_vgg16\n",
      " CNN-Cards\t\t        archive\t\t        logs\n",
      " DL-HW-1\t\t        checkpoints_mobilenet   logs_scratch\n",
      " Lab04-Segmentation\t        checkpoints_resnet50    prueba.ipynb\n",
      " Labs\t\t\t        checkpoints_scratch     requirements.txt\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85ff510d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 265 images belonging to 53 classes.\n",
      "Cargando modelo VGG16...\n",
      "‚ùå Error al cargar o evaluar el modelo:\n",
      "   TypeError: Error when deserializing class 'InputLayer' using config={'batch_shape': [None, 224, 224, 3], 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'input_layer_1'}.\n",
      "\n",
      "Exception encountered: Unrecognized keyword arguments: ['batch_shape']\n",
      "\n",
      "üí° Soluci√≥n alternativa: Intentando reconstruir el modelo...\n",
      "Cargando modelo VGG16...\n",
      "‚ùå Error al cargar o evaluar el modelo:\n",
      "   TypeError: Error when deserializing class 'InputLayer' using config={'batch_shape': [None, 224, 224, 3], 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'input_layer_1'}.\n",
      "\n",
      "Exception encountered: Unrecognized keyword arguments: ['batch_shape']\n",
      "\n",
      "üí° Soluci√≥n alternativa: Intentando reconstruir el modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-09 21:12:37.236655: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-12-09 21:12:37.336970: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-12-09 21:12:37.337008: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-12-09 21:12:37.339485: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-12-09 21:12:37.339535: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-12-09 21:12:37.339548: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-12-09 21:12:37.474004: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-12-09 21:12:37.474050: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-12-09 21:12:37.474060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-12-09 21:12:37.474082: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-12-09 21:12:37.474126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5564 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Tampoco funcion√≥ la reconstrucci√≥n:\n",
      "   ValueError: Cannot assign value to variable ' block1_conv1/kernel:0': Shape mismatch.The variable shape (3, 3, 3, 64), and the assigned value shape (512, 256, 3, 3) are incompatible.\n",
      "\n",
      "‚ö†Ô∏è  Es posible que necesites re-entrenar el modelo con la versi√≥n actual de TensorFlow.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "# Verificar que el modelo existe\n",
    "model_path = 'CNN-Cards/Models/VGG16_finetuned.h5'\n",
    "if not os.path.exists(model_path):\n",
    "    print(f'‚ùå Error: El modelo no existe en {model_path}')\n",
    "    print(f'\\nModelos disponibles en Models/:')\n",
    "    for f in os.listdir('Models'):\n",
    "        if f.endswith('.h5'):\n",
    "            print(f'  - {f}')\n",
    "else:\n",
    "    # Configurar generador de test\n",
    "    test_generator = ImageDataGenerator(rescale=1.0/255)\n",
    "    \n",
    "    test_dataset = test_generator.flow_from_directory(\n",
    "        'CNN-Cards/Datasets/Cards/test',\n",
    "        target_size=(224, 224),\n",
    "        class_mode='categorical',\n",
    "        batch_size=32,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Cargar modelo VGG16 con safe_mode para versiones incompatibles\n",
    "    print('Cargando modelo VGG16...')\n",
    "    try:\n",
    "        # Intentar cargar con safe_mode (TF 2.16+)\n",
    "        try:\n",
    "            vgg_model = tf.keras.models.load_model(model_path, compile=False, safe_mode=False)\n",
    "        except TypeError:\n",
    "            # Si safe_mode no est√° disponible, usar m√©todo antiguo\n",
    "            vgg_model = tf.keras.models.load_model(model_path, compile=False)\n",
    "        \n",
    "        # Re-compilar manualmente\n",
    "        vgg_model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        print('‚úì Modelo cargado exitosamente')\n",
    "        print(f'Arquitectura: {vgg_model.name if hasattr(vgg_model, \"name\") else \"VGG16\"}')\n",
    "        \n",
    "        # Evaluar\n",
    "        print('\\nEvaluando en test set...')\n",
    "        loss, accuracy = vgg_model.evaluate(test_dataset, verbose=1)\n",
    "        \n",
    "        print(f'\\n{\"=\"*50}')\n",
    "        print(f'VGG16 Fine-tuned Results:')\n",
    "        print(f'{\"=\"*50}')\n",
    "        print(f'Test Loss:     {loss:.4f}')\n",
    "        print(f'Test Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)')\n",
    "        print(f'{\"=\"*50}')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Error al cargar o evaluar el modelo:')\n",
    "        print(f'   {type(e).__name__}: {str(e)}')\n",
    "        print(f'\\nüí° Soluci√≥n alternativa: Intentando reconstruir el modelo...')\n",
    "        \n",
    "        # Alternativa: cargar solo los pesos\n",
    "        try:\n",
    "            from tensorflow.keras import regularizers\n",
    "            \n",
    "            # Reconstruir arquitectura VGG16\n",
    "            base_vgg16 = tf.keras.applications.VGG16(\n",
    "                include_top=False,\n",
    "                weights=None,  # No cargar pesos de ImageNet\n",
    "                input_shape=(224, 224, 3)\n",
    "            )\n",
    "            \n",
    "            inputs = tf.keras.layers.Input(shape=(224, 224, 3))\n",
    "            x = base_vgg16(inputs)\n",
    "            x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "            x = tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "            x = tf.keras.layers.Dropout(0.5)(x)\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "            x = tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "            x = tf.keras.layers.Dropout(0.4)(x)\n",
    "            x = tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "            x = tf.keras.layers.Dropout(0.3)(x)\n",
    "            outputs = tf.keras.layers.Dense(53, activation='softmax')(x)\n",
    "            \n",
    "            vgg_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "            \n",
    "            # Cargar solo los pesos\n",
    "            vgg_model.load_weights(model_path)\n",
    "            \n",
    "            vgg_model.compile(\n",
    "                optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy']\n",
    "            )\n",
    "            \n",
    "            print('‚úì Modelo reconstruido y pesos cargados exitosamente')\n",
    "            \n",
    "            # Evaluar\n",
    "            print('\\nEvaluando en test set...')\n",
    "            loss, accuracy = vgg_model.evaluate(test_dataset, verbose=1)\n",
    "            \n",
    "            print(f'\\n{\"=\"*50}')\n",
    "            print(f'VGG16 Fine-tuned Results (reconstruido):')\n",
    "            print(f'{\"=\"*50}')\n",
    "            print(f'Test Loss:     {loss:.4f}')\n",
    "            print(f'Test Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)')\n",
    "            print(f'{\"=\"*50}')\n",
    "            \n",
    "        except Exception as e2:\n",
    "            print(f'‚ùå Tampoco funcion√≥ la reconstrucci√≥n:')\n",
    "            print(f'   {type(e2).__name__}: {str(e2)}')\n",
    "            print(f'\\n‚ö†Ô∏è  Es posible que necesites re-entrenar el modelo con la versi√≥n actual de TensorFlow.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
